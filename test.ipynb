{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leanderdiaz-bone/Developer/scvi-tools/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/Users/leanderdiaz-bone/Developer/scvi-tools/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data\"\n",
    "url = (\n",
    "    \"https://github.com/YosefLab/scVI-data/raw/master/pbmc_10k_protein_v3.h5ad?raw=true\"\n",
    ")\n",
    "adata = sc.read(os.path.join(save_path, \"pbmc_10k_protein_v3.h5ad\"), backup_url=url)\n",
    "\n",
    "adata.layers[\"counts\"] = adata.X.copy()  # preserve counts\n",
    "sc.pp.normalize_total(adata, target_sum=10e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.raw = adata  # freeze the state in `.raw`\n",
    "\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata, flavor=\"seurat_v3\", layer=\"counts\", n_top_genes=1000, subset=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version.\n"
     ]
    }
   ],
   "source": [
    "scvi.model.SCVI.setup_anndata(adata, layer = \"counts\")\n",
    "model = scvi.model.SCVI(adata, n_latent = 10, prior_distribution = \"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain(max_epochs \u001b[39m=\u001b[39;49m \u001b[39m25\u001b[39;49m, plan_kwargs \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m5e-3\u001b[39;49m},check_val_every_n_epoch\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/model/base/_training_mixin.py:88\u001b[0m, in \u001b[0;36mUnsupervisedTrainingMixin.train\u001b[0;34m(self, max_epochs, use_gpu, accelerator, devices, train_size, validation_size, shuffle_set_split, batch_size, early_stopping, plan_kwargs, **trainer_kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m trainer_kwargs[es] \u001b[39m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m     early_stopping \u001b[39mif\u001b[39;00m es \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m trainer_kwargs\u001b[39m.\u001b[39mkeys() \u001b[39melse\u001b[39;00m trainer_kwargs[es]\n\u001b[1;32m     77\u001b[0m )\n\u001b[1;32m     78\u001b[0m runner \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_runner_cls(\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     80\u001b[0m     training_plan\u001b[39m=\u001b[39mtraining_plan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_kwargs,\n\u001b[1;32m     87\u001b[0m )\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m runner()\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/train/_trainrunner.py:99\u001b[0m, in \u001b[0;36mTrainRunner.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_splitter, \u001b[39m\"\u001b[39m\u001b[39mn_val\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_plan\u001b[39m.\u001b[39mn_obs_validation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_splitter\u001b[39m.\u001b[39mn_val\n\u001b[0;32m---> 99\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_plan, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_splitter)\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_history()\n\u001b[1;32m    102\u001b[0m \u001b[39m# data splitter only gets these attrs after fit\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/train/_trainer.py:186\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], PyroTrainingPlan):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[39m.\u001b[39mfilterwarnings(\n\u001b[1;32m    182\u001b[0m         action\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         category\u001b[39m=\u001b[39m\u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`LightningModule.configure_optimizers` returned `None`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 186\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 531\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    532\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    533\u001b[0m )\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_connector\u001b[39m.\u001b[39mattach_data(\n\u001b[1;32m    561\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39mval_dataloaders, datamodule\u001b[39m=\u001b[39mdatamodule\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    564\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    565\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    566\u001b[0m     ckpt_path,\n\u001b[1;32m    567\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    568\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m )\n\u001b[0;32m--> 570\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[1;32m    572\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    573\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    972\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m    977\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1017\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1018\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1019\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance()\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(data_fetcher)\n\u001b[1;32m    134\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py:218\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    217\u001b[0m         \u001b[39m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautomatic_optimization\u001b[39m.\u001b[39;49mrun(trainer\u001b[39m.\u001b[39;49moptimizers[\u001b[39m0\u001b[39;49m], kwargs)\n\u001b[1;32m    219\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:185\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         closure()\n\u001b[1;32m    180\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step(kwargs\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mbatch_idx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m), closure)\n\u001b[1;32m    187\u001b[0m result \u001b[39m=\u001b[39m closure\u001b[39m.\u001b[39mconsume_result()\n\u001b[1;32m    188\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mloss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:260\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_ready()\n\u001b[1;32m    259\u001b[0m \u001b[39m# model hook\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m call\u001b[39m.\u001b[39;49m_call_lightning_module_hook(\n\u001b[1;32m    261\u001b[0m     trainer,\n\u001b[1;32m    262\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39moptimizer_step\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    263\u001b[0m     trainer\u001b[39m.\u001b[39;49mcurrent_epoch,\n\u001b[1;32m    264\u001b[0m     batch_idx,\n\u001b[1;32m    265\u001b[0m     optimizer,\n\u001b[1;32m    266\u001b[0m     train_step_and_backward_closure,\n\u001b[1;32m    267\u001b[0m )\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim_progress\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep\u001b[39m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:140\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    142\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    143\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/core/module.py:1256\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimizer_step\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     epoch: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1224\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[39m    calls the optimizer.\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[39m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49moptimizer_closure)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py:155\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\u001b[39m\"\u001b[39m\u001b[39mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_strategy\u001b[39m.\u001b[39;49moptimizer_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer, closure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_after_step()\n\u001b[1;32m    159\u001b[0m \u001b[39mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:225\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(model, pl\u001b[39m.\u001b[39mLightningModule)\n\u001b[0;32m--> 225\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49moptimizer_step(optimizer, model\u001b[39m=\u001b[39;49mmodel, closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:114\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m closure \u001b[39m=\u001b[39m partial(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 114\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer\u001b[39m.\u001b[39;49mstep(closure\u001b[39m=\u001b[39;49mclosure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/torch/optim/adam.py:121\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39menable_grad():\n\u001b[0;32m--> 121\u001b[0m         loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_groups:\n\u001b[1;32m    124\u001b[0m     params_with_grad \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:101\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_wrap_closure\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     model: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     93\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     94\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     95\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[39m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     closure_result \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclosure(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\u001b[39m.\u001b[39mloss\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclosure\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 126\u001b[0m     step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_fn()\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m step_output\u001b[39m.\u001b[39mclosure_loss \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwarning_cache\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py:307\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    306\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39;49m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    308\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n\u001b[1;32m    310\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_result_cls\u001b[39m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[39m.\u001b[39maccumulate_grad_batches)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    290\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:367\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    366\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/train/_trainingplans.py:342\u001b[0m, in \u001b[0;36mTrainingPlan.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mkl_weight\u001b[39m\u001b[39m\"\u001b[39m: kl_weight})\n\u001b[1;32m    341\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mkl_weight\u001b[39m\u001b[39m\"\u001b[39m, kl_weight, on_step\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, on_epoch\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 342\u001b[0m _, _, scvi_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(batch, loss_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_kwargs)\n\u001b[1;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m\"\u001b[39m, scvi_loss\u001b[39m.\u001b[39mloss, on_epoch\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    344\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_and_log_metrics(scvi_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_metrics, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/train/_trainingplans.py:278\u001b[0m, in \u001b[0;36mTrainingPlan.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    277\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Passthrough to the module's forward method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Applications/Anaconda/anaconda3/envs/scvi-tools-dev/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/module/base/_decorators.py:32\u001b[0m, in \u001b[0;36mauto_move_data.<locals>.auto_transfer_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39m# decorator only necessary after training\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m device \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m({p\u001b[39m.\u001b[39mdevice \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters()})\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(device) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/module/base/_base_module.py:199\u001b[0m, in \u001b[0;36mBaseModuleClass.forward\u001b[0;34m(self, tensors, get_inference_input_kwargs, get_generative_input_kwargs, inference_kwargs, generative_kwargs, loss_kwargs, compute_loss)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39m@auto_move_data\u001b[39m\n\u001b[1;32m    166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    167\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[39m|\u001b[39m \u001b[39mtuple\u001b[39m[torch\u001b[39m.\u001b[39mTensor, torch\u001b[39m.\u001b[39mTensor, LossOutput]\n\u001b[1;32m    178\u001b[0m ):\n\u001b[1;32m    179\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Forward pass through the network.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \n\u001b[1;32m    181\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39m        another return value.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mreturn\u001b[39;00m _generic_forward(\n\u001b[1;32m    200\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    201\u001b[0m         tensors,\n\u001b[1;32m    202\u001b[0m         inference_kwargs,\n\u001b[1;32m    203\u001b[0m         generative_kwargs,\n\u001b[1;32m    204\u001b[0m         loss_kwargs,\n\u001b[1;32m    205\u001b[0m         get_inference_input_kwargs,\n\u001b[1;32m    206\u001b[0m         get_generative_input_kwargs,\n\u001b[1;32m    207\u001b[0m         compute_loss,\n\u001b[1;32m    208\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/module/base/_base_module.py:749\u001b[0m, in \u001b[0;36m_generic_forward\u001b[0;34m(module, tensors, inference_kwargs, generative_kwargs, loss_kwargs, get_inference_input_kwargs, get_generative_input_kwargs, compute_loss)\u001b[0m\n\u001b[1;32m    747\u001b[0m generative_outputs \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mgenerative(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerative_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerative_kwargs)\n\u001b[1;32m    748\u001b[0m \u001b[39mif\u001b[39;00m compute_loss:\n\u001b[0;32m--> 749\u001b[0m     losses \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49mloss(\n\u001b[1;32m    750\u001b[0m         tensors, inference_outputs, generative_outputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mloss_kwargs\n\u001b[1;32m    751\u001b[0m     )\n\u001b[1;32m    752\u001b[0m     \u001b[39mreturn\u001b[39;00m inference_outputs, generative_outputs, losses\n\u001b[1;32m    753\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Developer/scvi-tools/scvi/module/_vae.py:504\u001b[0m, in \u001b[0;36mVAE.loss\u001b[0;34m(self, tensors, inference_outputs, generative_outputs, kl_weight)\u001b[0m\n\u001b[1;32m    502\u001b[0m     log_q_zx \u001b[39m=\u001b[39m inference_outputs[\u001b[39m\"\u001b[39m\u001b[39mqz\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlog_prob(inference_outputs[\u001b[39m\"\u001b[39m\u001b[39mz\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    503\u001b[0m     log_p_z \u001b[39m=\u001b[39m generative_outputs[\u001b[39m\"\u001b[39m\u001b[39mpz\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mlog_prob(inference_outputs[\u001b[39m\"\u001b[39m\u001b[39mz\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 504\u001b[0m     kl_divergence_z \u001b[39m=\u001b[39m (log_q_zx\u001b[39m.\u001b[39;49msum(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39m-\u001b[39;49m log_p_z)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_observed_lib_size:\n\u001b[1;32m    507\u001b[0m     kl_divergence_l \u001b[39m=\u001b[39m kl(\n\u001b[1;32m    508\u001b[0m         inference_outputs[\u001b[39m\"\u001b[39m\u001b[39mql\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    509\u001b[0m         generative_outputs[\u001b[39m\"\u001b[39m\u001b[39mpl\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    510\u001b[0m     )\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model.train(max_epochs = 25, plan_kwargs = {\"lr\":5e-3},check_val_every_n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "Parameter containing:\n",
      "tensor([-0.0845, -0.0560, -0.0844, -0.0845,  1.3722, -0.0845, -0.0845,  0.3418,\n",
      "        -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0844, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "         0.0649, -0.0844, -0.0845, -0.0843, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0845, -0.0845,  0.2275, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0845,  0.0639, -0.0845, -0.0845, -0.0845,  0.0711, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0781, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0842, -0.0845, -0.0476, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0841,  1.2135, -0.0845,  0.0724, -0.0845, -0.0845, -0.0845, -0.0844,\n",
      "        -0.0845,  0.0989, -0.0845, -0.0845, -0.0845, -0.0845, -0.0844, -0.0844,\n",
      "         0.0829, -0.0845, -0.0845, -0.0845,  0.2901,  0.9544,  0.0572, -0.0845,\n",
      "        -0.0844, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0844,\n",
      "        -0.0845,  0.0879, -0.0845, -0.0842, -0.0843, -0.0845, -0.0845, -0.0845,\n",
      "         0.1266, -0.0844, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,  0.1323,\n",
      "        -0.0845, -0.0845, -0.0845, -0.0838, -0.0844, -0.0845, -0.0845, -0.0843,\n",
      "        -0.0845, -0.0845, -0.0840,  1.1227, -0.0844, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0845, -0.0845, -0.0845,  0.0358, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0844, -0.0845, -0.0845, -0.0845, -0.0457, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,  0.5931, -0.0845,\n",
      "         0.7394, -0.0845, -0.0845, -0.0845, -0.0845,  1.0146, -0.0845, -0.0844,\n",
      "        -0.0845, -0.0844, -0.0845, -0.0845, -0.0845,  2.1620, -0.0845, -0.0845,\n",
      "        -0.0608, -0.0845, -0.0845, -0.0845, -0.0844, -0.0844, -0.0844, -0.0844,\n",
      "         0.1577, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0844,  0.0593,\n",
      "        -0.0841, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845, -0.0845,\n",
      "        -0.0845, -0.0845, -0.0606, -0.0844, -0.0845, -0.0152, -0.0845,  0.4729],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.module.prior.pseudo_inputs)\n",
    "print(model.module.prior.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-tools-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
